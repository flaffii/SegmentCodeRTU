{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfde843a-0db4-453e-863f-55a467fa32ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import scipy.ndimage as ndimage\n",
    "import cv2\n",
    "import supervisely as sly\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# Konfigurācija pirms palaišanas\n",
    "class Config:\n",
    "    IMAGE_DIR = \"/mnt/c/dataset_folder/ds/img/\"\n",
    "    MASK_DIR = \"/mnt/c/dataset_folder/ds/ann/\"\n",
    "    MODEL_DIR = \"/mnt/c/saved_models/\"\n",
    "    META_PATH = os.path.join(MASK_DIR, \"meta.json\")\n",
    "    IMG_SIZE = (256, 256)\n",
    "    BATCH = 10\n",
    "    EPOCHS = 50\n",
    "    ENCODER = 'resnet34'\n",
    "    ENCODER_WEIGHTS = 'imagenet'\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    SELECTED_MODEL = 'FPN'  # Opcijas: 'Unet', 'Unet++' 'FPN', 'DeepLabV3', 'PSPNet' 'Segformer'\n",
    "\n",
    "os.makedirs(Config.MODEL_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90913e8-cb78-4c09-964c-082dc62147bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Albumentations Transformācijas\n",
    "transform = A.Compose([\n",
    "    A.Resize(*Config.IMG_SIZE),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# Supervisely Meta informācija\n",
    "with open(Config.META_PATH) as f:\n",
    "    meta = sly.ProjectMeta.from_json(json.load(f))\n",
    "\n",
    "# Dataset klase\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, meta, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.meta = meta\n",
    "        self.transform = transform\n",
    "        self.images = sorted([f for f in os.listdir(image_dir) if f.endswith('.png')])  # <- sorted for consistent ordering\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        mask_path = os.path.join(self.mask_dir, img_name + '.json')\n",
    "\n",
    "        image = sly.image.read(img_path)\n",
    "        h, w = image.shape[:2]\n",
    "        mask = np.zeros((h, w), dtype=np.uint8)\n",
    "\n",
    "        if os.path.exists(mask_path):\n",
    "            with open(mask_path) as f:\n",
    "                ann = sly.Annotation.from_json(json.load(f), self.meta)\n",
    "            for label in ann.labels:\n",
    "                try:\n",
    "                    label.draw(mask, color=255)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error drawing label on {img_name}: {e}\")\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented[\"image\"]\n",
    "            mask = augmented[\"mask\"].unsqueeze(0).float() / 255.0  # [1, H, W]\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "full_dataset = SegmentationDataset(Config.IMAGE_DIR, Config.MASK_DIR, meta, transform=transform)\n",
    "\n",
    "# fiksēts apmācības un pārbaudes sadalījums\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size], generator=generator)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=Config.BATCH, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=Config.BATCH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89407d15-ee7d-469a-a6e2-d3755a738ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeļa ielāde\n",
    "def get_model(name):\n",
    "    \"\"\"Get the model based on the selected model name.\"\"\"\n",
    "    model_dict = {\n",
    "        'Unet': smp.Unet,\n",
    "        'Unet++': smp.UnetPlusPlus,\n",
    "        'FPN': smp.FPN,\n",
    "        'DeepLabV3': smp.DeepLabV3,\n",
    "        'PSPNet': smp.PSPNet,\n",
    "        'Segformer': smp.Segformer\n",
    "    }\n",
    "    return model_dict[name](\n",
    "        encoder_name=Config.ENCODER,\n",
    "        encoder_weights=Config.ENCODER_WEIGHTS,\n",
    "        in_channels=3,\n",
    "        classes=1,\n",
    "        activation=None\n",
    "    ).to(Config.DEVICE)\n",
    "\n",
    "model = get_model(Config.SELECTED_MODEL)\n",
    "\n",
    "# zaudējumu funkcija\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# rādītāji\n",
    "def compute_metrics(preds, targets):\n",
    "    preds = torch.sigmoid(preds) > 0.5\n",
    "    targets = targets > 0.5\n",
    "\n",
    "    intersection = (preds & targets).float().sum((1, 2, 3))\n",
    "    union = (preds | targets).float().sum((1, 2, 3))\n",
    "    iou = (intersection + 1e-6) / (union + 1e-6)\n",
    "    return iou.mean().item()\n",
    "\n",
    "# funkcijas\n",
    "def train_one_epoch(model, loader, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    epoch_iou = 0.0\n",
    "\n",
    "    for images, masks in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        images = images.to(Config.DEVICE)\n",
    "        masks = masks.to(Config.DEVICE)\n",
    "\n",
    "        preds = model(images)\n",
    "        loss = loss_fn(preds, masks)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_iou += compute_metrics(preds, masks)\n",
    "\n",
    "    return epoch_loss / len(loader), epoch_iou / len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, loss_fn):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_iou = 0.0\n",
    "\n",
    "    for images, masks in tqdm(loader, desc=\"Validation\", leave=False):\n",
    "        images = images.to(Config.DEVICE)\n",
    "        masks = masks.to(Config.DEVICE)\n",
    "\n",
    "        preds = model(images)\n",
    "        loss = loss_fn(preds, masks)\n",
    "\n",
    "        val_loss += loss.item()\n",
    "        val_iou += compute_metrics(preds, masks)\n",
    "\n",
    "    return val_loss / len(loader), val_iou / len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2e8787-62a6-494f-901c-c7b222967f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# galvenā apmācība (izlaist bloku pārbaudes gadījumā)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "best_val_loss = float('inf')  \n",
    "for epoch in range(Config.EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{Config.EPOCHS}\")\n",
    "\n",
    "    train_loss, train_iou = train_one_epoch(model, train_loader, loss_fn, optimizer)\n",
    "    val_loss, val_iou = evaluate(model, val_loader, loss_fn)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f}, IoU: {train_iou:.4f}\")\n",
    "    print(f\"Val   Loss: {val_loss:.4f}, IoU: {val_iou:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        SAVED_MODEL_NAME = f\"{Config.SELECTED_MODEL}_best.pt\" # saglabā modeli ar tā nosaukumu\n",
    "        model_path = os.path.join(Config.MODEL_DIR, SAVED_MODEL_NAME)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(f\"✅ Saved new best model at epoch {epoch + 1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea541cce-12a9-4934-96d3-22470e6e448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pārbaudes metriku aprēķinu klase\n",
    "class TorchSegmentationEvaluator:\n",
    "    def __init__(self, model, val_dataset, threshold=0.5, min_object_size=100):\n",
    "        self.model = model\n",
    "        self.dataset = val_dataset\n",
    "        self.threshold = threshold\n",
    "        self.min_object_size = min_object_size\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return torch.sigmoid(x).cpu().numpy()\n",
    "\n",
    "    def _to_numpy(self, tensor):\n",
    "        return tensor.squeeze().cpu().numpy()\n",
    "\n",
    "    def _get_connected_components(self, mask):\n",
    "        labeled, num_features = ndimage.label(mask)\n",
    "        objects = []\n",
    "        for i in range(1, num_features + 1):\n",
    "            obj_mask = (labeled == i)\n",
    "            if np.sum(obj_mask) >= self.min_object_size:\n",
    "                objects.append(obj_mask)\n",
    "        return objects\n",
    "\n",
    "    def calculate_iou(self, y_true, y_pred):\n",
    "        intersection = np.sum(y_true * y_pred)\n",
    "        union = np.sum(y_true) + np.sum(y_pred) - intersection\n",
    "        return intersection / (union + 1e-6)\n",
    "\n",
    "    def evaluate(self):\n",
    "        y_true_all = []\n",
    "        y_pred_all = []\n",
    "\n",
    "        tp = fp = fn = tn = 0\n",
    "        false_detections = missed_detections = good_detections = 0\n",
    "        total_objects = 0\n",
    "\n",
    "        for img, mask in tqdm(self.dataset, desc=\"Evaluating\"):\n",
    "            img = img.unsqueeze(0).to(Config.DEVICE)\n",
    "            pred = self.model(img)\n",
    "            pred = (torch.sigmoid(pred) > self.threshold).float().squeeze().cpu().numpy()\n",
    "            true = (mask.squeeze().numpy() > self.threshold).astype(np.int32)\n",
    "\n",
    "            y_true_all.extend(true.flatten())\n",
    "            y_pred_all.extend(pred.flatten())\n",
    "\n",
    "            true_objs = self._get_connected_components(true)\n",
    "            pred_objs = self._get_connected_components(pred)\n",
    "\n",
    "            if not true_objs:\n",
    "                false_detections += len(pred_objs)\n",
    "            elif not pred_objs:\n",
    "                missed_detections += len(true_objs)\n",
    "            else:\n",
    "                for true_obj in true_objs:\n",
    "                    iou_max = max(self.calculate_iou(true_obj, pred_obj) for pred_obj in pred_objs)\n",
    "                    if iou_max > 0.5:\n",
    "                        good_detections += 1\n",
    "                    else:\n",
    "                        missed_detections += 1\n",
    "\n",
    "                false_detections += max(0, len(pred_objs) - len(true_objs))\n",
    "\n",
    "            total_objects += len(true_objs)\n",
    "\n",
    "        return {\n",
    "            'pixel_accuracy': accuracy_score(y_true_all, y_pred_all),\n",
    "            'precision': precision_score(y_true_all, y_pred_all),\n",
    "            'recall': recall_score(y_true_all, y_pred_all),\n",
    "            'IoU': self.calculate_iou(np.array(y_true_all), np.array(y_pred_all)),\n",
    "            'Dice': f1_score(y_true_all, y_pred_all),\n",
    "            'object_detection_rate': good_detections / (total_objects + 1e-6),\n",
    "            'false_discovery_rate': false_detections / (false_detections + good_detections + 1e-6),\n",
    "            'missed_object_rate': missed_detections / (total_objects + 1e-6),\n",
    "            'total_objects': total_objects,\n",
    "            'false_detections': false_detections,\n",
    "            'missed_detections': missed_detections,\n",
    "            'good_detections': good_detections\n",
    "        }\n",
    "\n",
    "    def visualize_samples(self, n=3, show_analysis=True):\n",
    "        plt.figure(figsize=(18, 5 * n))\n",
    "        for i in range(n):\n",
    "            img, mask = self.dataset[i]\n",
    "            pred = torch.sigmoid(self.model(img.unsqueeze(0).to(Config.DEVICE))).squeeze().cpu().detach().numpy()\n",
    "            pred_bin = (pred > self.threshold).astype(np.uint8)\n",
    "            true_bin = (mask.squeeze().numpy() > self.threshold).astype(np.uint8)\n",
    "\n",
    "            plt.subplot(n, 4, i * 4 + 1)\n",
    "            plt.imshow(self.denormalize(img))\n",
    "            plt.title(\"Image\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            plt.subplot(n, 4, i * 4 + 2)\n",
    "            plt.imshow(true_bin, cmap='gray')\n",
    "            plt.title(\"Ground Truth\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            plt.subplot(n, 4, i * 4 + 3)\n",
    "            plt.imshow(pred_bin, cmap='gray')\n",
    "            plt.title(\"Prediction\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            if show_analysis:\n",
    "                error_mask = np.zeros_like(true_bin)\n",
    "                error_mask[(true_bin == 1) & (pred_bin == 0)] = 1  # FN\n",
    "                error_mask[(true_bin == 0) & (pred_bin == 1)] = 2  # FP\n",
    "                error_mask[(true_bin == 1) & (pred_bin == 1)] = 3  # TP\n",
    "\n",
    "                plt.subplot(n, 4, i * 4 + 4)\n",
    "                plt.imshow(error_mask, cmap='jet', vmin=0, vmax=3)\n",
    "                plt.title(\"Errors\")\n",
    "                plt.axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "# (De-normalize) Tikai attēlošanai\n",
    "    def denormalize(self, tensor):\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        img = tensor.permute(1, 2, 0).cpu().numpy()  # CxHxW -> HxWxC\n",
    "        img = (img * std + mean)  \n",
    "        img = np.clip(img, 0, 1)\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70e187c-c68a-4cef-bafb-487a7428e9f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ielādē modeli pārbaudei un izvada rezultātus\n",
    "loaded_model = get_model('FPN') # Options: 'Unet', 'Unet++' 'FPN', 'DeepLabV3', 'PSPNet' 'Segformer'\n",
    "model_path = os.path.join(Config.MODEL_DIR, f\"{Config.SELECTED_MODEL}_best.pt\")\n",
    "loaded_model.load_state_dict(torch.load(model_path))\n",
    "loaded_model.eval().to(Config.DEVICE)\n",
    "\n",
    "evaluator = TorchSegmentationEvaluator(loaded_model, val_dataset)\n",
    "\n",
    "metrics = evaluator.evaluate()\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\" if isinstance(v, float) else f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea7fc0a-ccda-4d6e-ba92-d7ab774cf8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vizualizē rezultātus (50)\n",
    "evaluator.visualize_samples(n=50, show_analysis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b227eb0c-e391-4307-9912-be19ecb2af3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
