{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecdab3e0-3174-4f16-9e6e-ba7b304f6457",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 07:02:23.268651: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743393743.284622  139989 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743393743.288855  139989 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743393743.304576  139989 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743393743.304623  139989 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743393743.304625  139989 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743393743.304627  139989 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-31 07:02:23.309559: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Dropout, Activation, Input, Conv2D, BatchNormalization, ReLU,\n",
    "    MaxPooling2D, UpSampling2D, Concatenate, Multiply, Add\n",
    ")\n",
    "from tensorflow.keras.models import ModelQ\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras.losses import Loss\n",
    "import supervisely as sly\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.metrics import adapted_rand_error\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import keras\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from scipy import ndimage\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# pielāgošana\n",
    "class Config:\n",
    "    IMAGE_DIR = \"/mnt/c/dataset_folder/ds/img/\"\n",
    "    MASK_DIR = \"/mnt/c/dataset_folder/ds/ann/\"\n",
    "    MODEL_DIR = \"/mnt/c/saved_models/\"\n",
    "    IMG_SIZE = (256, 256)\n",
    "    BATCH = 3\n",
    "    AUTO_THRESH = False\n",
    "\n",
    "os.makedirs(Config.MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deb42031-be61-4371-bfa8-6280473addb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|█████████████████████████████████████████████████████████████████| 780/780 [00:42<00:00, 18.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# Datu ielāde\n",
    "def load_images_and_masks(img_dir, mask_dir, meta, target_size):\n",
    "    images, masks = [], []\n",
    "    for img_name in tqdm(os.listdir(img_dir), desc=\"Loading images\"):\n",
    "        if not img_name.endswith(\".png\"): continue\n",
    "        \n",
    "        img_path = os.path.join(img_dir, img_name)\n",
    "        orig_img = sly.image.read(img_path)\n",
    "        h, w = orig_img.shape[:2]\n",
    "        mask = np.zeros((h, w), dtype=np.uint8)\n",
    "        mask_path = os.path.join(mask_dir, img_name + \".json\")\n",
    "        if os.path.exists(mask_path):\n",
    "            with open(mask_path) as f:\n",
    "                ann = sly.Annotation.from_json(json.load(f), meta)\n",
    "            for label in ann.labels:\n",
    "                try:\n",
    "                    label.draw(mask, color=255)\n",
    "                except Exception as e:\n",
    "                    print(f\"Couldn't draw label on {img_name}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "        image = cv2.resize(orig_img, target_size) / 255.0\n",
    "        mask = cv2.resize(mask, target_size, interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        masks.append(mask.astype(np.float32)[..., None] / 255.0)\n",
    "        images.append(image)\n",
    "    \n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "with open(os.path.join(Config.MASK_DIR, \"meta.json\")) as f:\n",
    "    meta = sly.ProjectMeta.from_json(json.load(f))\n",
    "\n",
    "images, masks = load_images_and_masks(Config.IMAGE_DIR, Config.MASK_DIR, meta, Config.IMG_SIZE)\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, masks, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7091e13-15e2-4065-8a52-fa722299f175",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743393791.573834  139989 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5592 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:26:00.0, compute capability: 8.6\n",
      "2025-03-31 07:03:12.801077: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 981467136 exceeds 10% of free system memory.\n",
      "2025-03-31 07:03:13.529074: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 981467136 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 07:03:13.792959: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 981467136 exceeds 10% of free system memory.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743393801.346585  140100 service.cc:152] XLA service 0x7f3350003b70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1743393801.346625  140100 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Ti, Compute Capability 8.6\n",
      "2025-03-31 07:03:21.539765: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1743393802.616779  140100 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  2/208\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - accuracy: 0.4293 - loss: 0.9308 - mean_io_u: 0.4749   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743393816.192735  140100 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6002 - loss: 0.8346 - mean_io_u: 0.4632 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 07:03:54.429794: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng11{k2=4,k3=0} for conv %cudnn-conv-bias-activation.72 = (f32[32,64,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,128,128]{3,2,1,0} %bitcast.2838, f32[64,128,3,3]{3,2,1,0} %bitcast.2845, f32[64]{0} %bitcast.2847), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_12_1/convolution\" source_file=\"/home/meowo/miniconda3/envs/tfenviten/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-03-31 07:03:54.491728: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.18815012s\n",
      "Trying algorithm eng11{k2=4,k3=0} for conv %cudnn-conv-bias-activation.72 = (f32[32,64,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,128,128]{3,2,1,0} %bitcast.2838, f32[64,128,3,3]{3,2,1,0} %bitcast.2845, f32[64]{0} %bitcast.2847), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_12_1/convolution\" source_file=\"/home/meowo/miniconda3/envs/tfenviten/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 158ms/step - accuracy: 0.6007 - loss: 0.8344 - mean_io_u: 0.4632 - val_accuracy: 0.9235 - val_loss: 0.8963 - val_mean_io_u: 0.4618\n",
      "Epoch 2/25\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - accuracy: 0.8239 - loss: 0.7393 - mean_io_u: 0.4771 - val_accuracy: 0.9276 - val_loss: 0.8493 - val_mean_io_u: 0.4633\n",
      "Epoch 3/25\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.8725 - loss: 0.6966 - mean_io_u: 0.5103 - val_accuracy: 0.9366 - val_loss: 0.7157 - val_mean_io_u: 0.4856\n",
      "Epoch 4/25\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.9027 - loss: 0.6566 - mean_io_u: 0.5253 - val_accuracy: 0.9394 - val_loss: 0.6605 - val_mean_io_u: 0.5078\n",
      "Epoch 5/25\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.9206 - loss: 0.6141 - mean_io_u: 0.5370 - val_accuracy: 0.9416 - val_loss: 0.6086 - val_mean_io_u: 0.5255\n",
      "Epoch 6/25\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.9297 - loss: 0.5695 - mean_io_u: 0.5390 - val_accuracy: 0.9405 - val_loss: 0.5672 - val_mean_io_u: 0.5583\n",
      "Epoch 7/25\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.9372 - loss: 0.5275 - mean_io_u: 0.5404 - val_accuracy: 0.9340 - val_loss: 0.5933 - val_mean_io_u: 0.5160\n",
      "Epoch 8/25\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - accuracy: 0.9410 - loss: 0.4878 - mean_io_u: 0.5428 - val_accuracy: 0.9330 - val_loss: 0.5434 - val_mean_io_u: 0.5913\n",
      "Epoch 9/25\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - accuracy: 0.9387 - loss: 0.4665 - mean_io_u: 0.5386 - val_accuracy: 0.9412 - val_loss: 0.4971 - val_mean_io_u: 0.5675\n",
      "Epoch 10/25\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - accuracy: 0.9418 - loss: 0.4327 - mean_io_u: 0.5438 - val_accuracy: 0.9431 - val_loss: 0.4800 - val_mean_io_u: 0.5416\n",
      "Epoch 11/25\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.9451 - loss: 0.3987 - mean_io_u: 0.5430 - val_accuracy: 0.9430 - val_loss: 0.4720 - val_mean_io_u: 0.5859\n",
      "Epoch 12/25\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - accuracy: 0.9458 - loss: 0.3779 - mean_io_u: 0.5420 - val_accuracy: 0.9452 - val_loss: 0.4314 - val_mean_io_u: 0.5585\n",
      "Epoch 13/25\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.9465 - loss: 0.3633 - mean_io_u: 0.5430 - val_accuracy: 0.9405 - val_loss: 0.4961 - val_mean_io_u: 0.5166\n",
      "Epoch 14/25\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.9458 - loss: 0.3564 - mean_io_u: 0.5409 - val_accuracy: 0.9451 - val_loss: 0.4215 - val_mean_io_u: 0.5552\n",
      "Epoch 15/25\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - accuracy: 0.9473 - loss: 0.3292 - mean_io_u: 0.5434 - val_accuracy: 0.9465 - val_loss: 0.4258 - val_mean_io_u: 0.5555\n",
      "Epoch 16/25\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 46ms/step - accuracy: 0.9487 - loss: 0.3219 - mean_io_u: 0.5480 - val_accuracy: 0.9469 - val_loss: 0.4173 - val_mean_io_u: 0.5943\n",
      "Epoch 17/25\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - accuracy: 0.9487 - loss: 0.3144 - mean_io_u: 0.5475 - val_accuracy: 0.9471 - val_loss: 0.4071 - val_mean_io_u: 0.5671\n",
      "Epoch 18/25\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.9492 - loss: 0.3042 - mean_io_u: 0.5465 - val_accuracy: 0.9436 - val_loss: 0.4287 - val_mean_io_u: 0.5293\n",
      "Epoch 19/25\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.9496 - loss: 0.2904 - mean_io_u: 0.5450 - val_accuracy: 0.9434 - val_loss: 0.4042 - val_mean_io_u: 0.5783\n",
      "Epoch 20/25\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.9487 - loss: 0.2915 - mean_io_u: 0.5437 - val_accuracy: 0.9467 - val_loss: 0.3829 - val_mean_io_u: 0.5613\n",
      "Epoch 21/25\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.9498 - loss: 0.2857 - mean_io_u: 0.5494 - val_accuracy: 0.9466 - val_loss: 0.3817 - val_mean_io_u: 0.5808\n",
      "Epoch 22/25\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.9505 - loss: 0.2752 - mean_io_u: 0.5539 - val_accuracy: 0.9458 - val_loss: 0.3915 - val_mean_io_u: 0.5602\n",
      "Epoch 23/25\n",
      "\u001b[1m149/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.9508 - loss: 0.2710 - mean_io_u: 0.5540"
     ]
    }
   ],
   "source": [
    "# Modeļa arhitektūra\n",
    "def unet_model(input_size=(256, 256, 3)):\n",
    "    inputs = layers.Input(input_size)\n",
    "    \n",
    "    e1 = Conv2D(32, 3, padding='same')(inputs)\n",
    "    e1 = BatchNormalization()(e1)\n",
    "    e1 = Activation('relu')(e1)\n",
    "    e1 = Conv2D(32, 3, padding='same')(e1)\n",
    "    e1 = BatchNormalization()(e1)\n",
    "    e1 = Activation('relu')(e1)\n",
    "    p1 = MaxPooling2D()(e1)\n",
    "    p1 = Dropout(0.1)(p1)\n",
    "    \n",
    "    e2 = Conv2D(64, 3, padding='same')(p1)\n",
    "    e2 = BatchNormalization()(e2)\n",
    "    e2 = Activation('relu')(e2)\n",
    "    e2 = Conv2D(64, 3, padding='same')(e2)\n",
    "    e2 = BatchNormalization()(e2)\n",
    "    e2 = Activation('relu')(e2)\n",
    "    p2 = MaxPooling2D()(e2)\n",
    "    p2 = Dropout(0.2)(p2)\n",
    "    \n",
    "    e3 = Conv2D(128, 3, padding='same')(p2)\n",
    "    e3 = BatchNormalization()(e3)\n",
    "    e3 = Activation('relu')(e3)\n",
    "    e3 = Conv2D(128, 3, padding='same')(e3)\n",
    "    e3 = BatchNormalization()(e3)\n",
    "    e3 = Activation('relu')(e3)\n",
    "    p3 = MaxPooling2D()(e3)\n",
    "    p3 = Dropout(0.3)(p3)\n",
    "    \n",
    "    m = Conv2D(256, 3, dilation_rate=2, padding='same')(p3)\n",
    "    m = BatchNormalization()(m)\n",
    "    m = Activation('relu')(m)\n",
    "    m = Conv2D(256, 3, dilation_rate=2, padding='same')(m)\n",
    "    m = BatchNormalization()(m)\n",
    "    m = Activation('relu')(m)\n",
    "    m = Dropout(0.4)(m)\n",
    "    \n",
    "    d1 = UpSampling2D()(m)\n",
    "    d1 = Conv2D(128, 2, padding='same')(d1)\n",
    "    d1 = BatchNormalization()(d1)\n",
    "    d1 = Activation('relu')(d1)\n",
    "    d1 = Concatenate()([d1, e3])\n",
    "    d1 = Conv2D(128, 3, padding='same')(d1)\n",
    "    d1 = BatchNormalization()(d1)\n",
    "    d1 = Activation('relu')(d1)\n",
    "    d1 = Conv2D(128, 3, padding='same')(d1)\n",
    "    d1 = BatchNormalization()(d1)\n",
    "    d1 = Activation('relu')(d1)\n",
    "    \n",
    "    d2 = UpSampling2D()(d1)\n",
    "    d2 = Conv2D(64, 2, padding='same')(d2)\n",
    "    d2 = BatchNormalization()(d2)\n",
    "    d2 = Activation('relu')(d2)\n",
    "    d2 = Concatenate()([d2, e2])\n",
    "    d2 = Conv2D(64, 3, padding='same')(d2)\n",
    "    d2 = BatchNormalization()(d2)\n",
    "    d2 = Activation('relu')(d2)\n",
    "    d2 = Conv2D(64, 3, padding='same')(d2)\n",
    "    d2 = BatchNormalization()(d2)\n",
    "    d2 = Activation('relu')(d2)\n",
    "    \n",
    "    d3 = UpSampling2D()(d2)\n",
    "    d3 = Conv2D(32, 2, padding='same')(d3)\n",
    "    d3 = BatchNormalization()(d3)\n",
    "    d3 = Activation('relu')(d3)\n",
    "    d3 = Concatenate()([d3, e1])\n",
    "    d3 = Conv2D(32, 3, padding='same')(d3)\n",
    "    d3 = BatchNormalization()(d3)\n",
    "    d3 = Activation('relu')(d3)\n",
    "    d3 = Conv2D(32, 3, padding='same')(d3)\n",
    "    d3 = BatchNormalization()(d3)\n",
    "    d3 = Activation('relu')(d3)\n",
    "    \n",
    "    attention = Conv2D(1, 1, activation='sigmoid')(d3)\n",
    "    d3 = Multiply()([d3, attention])\n",
    "    \n",
    "    outputs = Conv2D(1, 1, activation='sigmoid')(d3)\n",
    "    \n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "class FocusedSegmentationLoss(Loss):\n",
    "    def __init__(self, alpha=0.8, beta=0.2, gamma=1.5, name='focused_loss'):\n",
    "        super().__init__(name=name)\n",
    "        self.alpha = tf.constant(alpha, dtype=tf.float32)\n",
    "        self.beta = tf.constant(beta, dtype=tf.float32)\n",
    "        self.gamma = tf.constant(gamma, dtype=tf.float32)\n",
    "        self.smooth = tf.constant(1e-6, dtype=tf.float32)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        tp = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "        fp = tf.reduce_sum((1 - y_true) * y_pred, axis=[1, 2, 3])\n",
    "        fn = tf.reduce_sum(y_true * (1 - y_pred), axis=[1, 2, 3])\n",
    "        tversky = (tp + self.smooth) / (tp + self.alpha * fp + self.beta * fn + self.smooth)\n",
    "        focal_tversky = tf.pow(1 - tversky, self.gamma)\n",
    "        \n",
    "        if len(y_true.shape) == 4:\n",
    "            y_true_dx, y_true_dy = tf.image.image_gradients(y_true)\n",
    "            y_pred_dx, y_pred_dy = tf.image.image_gradients(y_pred)\n",
    "            boundary_loss = tf.reduce_mean(\n",
    "                tf.abs(y_true_dx - y_pred_dx) + tf.abs(y_true_dy - y_pred_dy),\n",
    "                axis=[1, 2, 3]\n",
    "            )\n",
    "        else:\n",
    "            boundary_loss = 0.0\n",
    "        \n",
    "        return focal_tversky + 0.05 * boundary_loss\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'alpha': float(self.alpha), 'beta': float(self.beta), 'gamma': float(self.gamma)}\n",
    "\n",
    "model = unet_model()\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss=FocusedSegmentationLoss(alpha=0.9, beta=0.1, gamma=1.5),\n",
    "    metrics=['accuracy', tf.keras.metrics.MeanIoU(2)]\n",
    ")\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    os.path.join(Config.MODEL_DIR, 'Segment_modelis_1.keras'),\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss'\n",
    ")\n",
    "\n",
    "try:\n",
    "    model.fit(\n",
    "        tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(Config.BATCH),\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=25,\n",
    "        callbacks=[checkpoint]\n",
    "    )\n",
    "except tf.errors.ResourceExhaustedError:\n",
    "    print(\"Atmiņas trūkums.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad911f7-514e-4013-ae6c-d7d4d0de8267",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images, masks, test_size=0.2, random_state=42)\n",
    "\n",
    "class SegmentationEvaluator:\n",
    "    def __init__(self, model, X_test, y_test):\n",
    "        self.model = model\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.threshold = 0.1  # Default threshold\n",
    "        self.min_object_size = 100  # Minimum pixels to consider an object\n",
    "    \n",
    "    def calculate_iou(self, y_true, y_pred):\n",
    "        intersection = np.sum(y_true * y_pred)\n",
    "        union = np.sum(y_true) + np.sum(y_pred) - intersection\n",
    "        return intersection / (union + 1e-7)\n",
    "    \n",
    "    def find_optimal_threshold(self, n_samples=100):\n",
    "        preds = self.model.predict(self.X_test[:n_samples], verbose=0)\n",
    "        thresholds = np.linspace(0.1, 0.9, 20)\n",
    "        best_thresh = 0.5\n",
    "        best_dice = 0\n",
    "        \n",
    "        for thresh in thresholds:\n",
    "            y_true_binary = (self.y_test[:n_samples] > thresh).astype(np.int32)\n",
    "            y_pred_binary = (preds > thresh).astype(np.int32)\n",
    "            dice = f1_score(y_true_binary.flatten(), y_pred_binary.flatten())\n",
    "            \n",
    "            if dice > best_dice:\n",
    "                best_dice = dice\n",
    "                best_thresh = thresh\n",
    "        \n",
    "        self.threshold = best_thresh\n",
    "        return best_thresh\n",
    "    \n",
    "    def _get_connected_components(self, mask):\n",
    "        labeled, num_features = ndimage.label(mask)\n",
    "        objects = []\n",
    "        for i in range(1, num_features+1):\n",
    "            obj_mask = (labeled == i)\n",
    "            if np.sum(obj_mask) >= self.min_object_size:\n",
    "                objects.append(obj_mask)\n",
    "        return objects\n",
    "    \n",
    "    def evaluate(self):\n",
    "        preds = self.model.predict(self.X_test, verbose=0)\n",
    "        \n",
    "        y_true_binary = (self.y_test > self.threshold).astype(np.int32)\n",
    "        y_pred_binary = (preds > self.threshold).astype(np.int32)\n",
    "        \n",
    "        tp = np.sum(y_true_binary * y_pred_binary)  # True positives\n",
    "        fp = np.sum((1-y_true_binary) * y_pred_binary)  # False positives\n",
    "        fn = np.sum(y_true_binary * (1-y_pred_binary))  # False negatives\n",
    "        tn = np.sum((1-y_true_binary) * (1-y_pred_binary))  # True negatives\n",
    "        \n",
    "        false_detections = 0\n",
    "        missed_detections = 0\n",
    "        good_detections = 0\n",
    "        \n",
    "        for i in range(len(self.X_test)):\n",
    "            true_objects = self._get_connected_components(y_true_binary[i])\n",
    "            pred_objects = self._get_connected_components(y_pred_binary[i])\n",
    "            \n",
    "            if len(true_objects) == 0:\n",
    "                false_detections += len(pred_objects)\n",
    "            \n",
    "            else:\n",
    "                if len(pred_objects) == 0:\n",
    "                    missed_detections += len(true_objects)\n",
    "                else:\n",
    "                    for true_obj in true_objects:\n",
    "                        max_iou = 0\n",
    "                        for pred_obj in pred_objects:\n",
    "                            iou = self.calculate_iou(true_obj, pred_obj)\n",
    "                            if iou > max_iou:\n",
    "                                max_iou = iou\n",
    "                        if max_iou > 0.5:\n",
    "                            good_detections += 1\n",
    "                        else:\n",
    "                            missed_detections += 1\n",
    "                    \n",
    "                    false_detections += max(0, len(pred_objects) - len(true_objects))\n",
    "        \n",
    "        total_objects = np.sum([len(self._get_connected_components(m)) for m in y_true_binary])\n",
    "        \n",
    "        return {\n",
    "            'pixel_accuracy': accuracy_score(y_true_binary.flatten(), y_pred_binary.flatten()),\n",
    "            'precision': precision_score(y_true_binary.flatten(), y_pred_binary.flatten()),\n",
    "            'recall': recall_score(y_true_binary.flatten(), y_pred_binary.flatten()),\n",
    "            'IoU': self.calculate_iou(y_true_binary, y_pred_binary),\n",
    "            'Dice': f1_score(y_true_binary.flatten(), y_pred_binary.flatten()),\n",
    "            \n",
    "            'true_positives': tp,\n",
    "            'false_positives': fp,\n",
    "            'true_negatives': tn,\n",
    "            'false_negatives': fn,\n",
    "            \n",
    "            'object_detection_rate': good_detections / (total_objects + 1e-7),\n",
    "            'false_discovery_rate': false_detections / (false_detections + good_detections + 1e-7),\n",
    "            'missed_object_rate': missed_detections / (total_objects + 1e-7),\n",
    "            'total_objects': total_objects,\n",
    "            'false_detections': false_detections,\n",
    "            'missed_detections': missed_detections,\n",
    "            'good_detections': good_detections,\n",
    "            \n",
    "            'threshold': self.threshold\n",
    "        }\n",
    "    \n",
    "    def visualize_samples(self, n_samples=3, show_analysis=False):\n",
    "        preds = self.model.predict(self.X_test[:n_samples], verbose=0)\n",
    "        \n",
    "        plt.figure(figsize=(18, 5*n_samples))\n",
    "        for i in range(n_samples):\n",
    "            y_true_bin = (self.y_test[i] > self.threshold).astype(np.int32)\n",
    "            y_pred_bin = (preds[i] > self.threshold).astype(np.int32)\n",
    "            \n",
    "            plt.subplot(n_samples, 4, i*4+1)\n",
    "            plt.imshow(self.X_test[i])\n",
    "            plt.title(f\"Image {i+1}\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.subplot(n_samples, 4, i*4+2)\n",
    "            plt.imshow(y_true_bin.squeeze(), cmap='gray')\n",
    "            plt.title(\"True Mask\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.subplot(n_samples, 4, i*4+3)\n",
    "            plt.imshow(y_pred_bin.squeeze(), cmap='gray')\n",
    "            plt.title(f\"Predicted (Threshold={self.threshold:.2f})\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            if show_analysis:\n",
    "                plt.subplot(n_samples, 4, i*4+4)\n",
    "                error_mask = np.zeros_like(y_true_bin)\n",
    "                error_mask[(y_true_bin==1)&(y_pred_bin==0)] = 1  \n",
    "                error_mask[(y_true_bin==0)&(y_pred_bin==1)] = 2  \n",
    "                error_mask[(y_true_bin==1)&(y_pred_bin==1)] = 3  \n",
    "                \n",
    "                plt.imshow(error_mask.squeeze(), cmap='jet', vmin=0, vmax=3)\n",
    "                plt.title(\"Errors: FN(LBlue), TN(Blue), FP(Yellow), TP(Red)\")\n",
    "                plt.axis('off')\n",
    "                plt.colorbar(ticks=[0,1,2,3], label='Error Type')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "evaluator = SegmentationEvaluator(model, X_test, y_test)\n",
    "print(\"Optimal threshold:\", evaluator.find_optimal_threshold())\n",
    "metrics = evaluator.evaluate()\n",
    "\n",
    "print(\"\\nDetailed Metrics:\")\n",
    "print(f\"Pixel Accuracy: {metrics['pixel_accuracy']:.4f}\")\n",
    "print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "print(f\"IoU: {metrics['IoU']:.4f}\")\n",
    "print(f\"Dice: {metrics['Dice']:.4f}\")\n",
    "\n",
    "print(\"\\nPixel Counts:\")\n",
    "print(f\"True Positives: {metrics['true_positives']}\")\n",
    "print(f\"False Positives: {metrics['false_positives']}\")\n",
    "print(f\"True Negatives: {metrics['true_negatives']}\")\n",
    "print(f\"False Negatives: {metrics['false_negatives']}\")\n",
    "\n",
    "print(\"\\nObject Detection:\")\n",
    "print(f\"Total Objects: {metrics['total_objects']}\")\n",
    "print(f\"Good Detections: {metrics['good_detections']}\")\n",
    "print(f\"Missed Detections: {metrics['missed_detections']}\")\n",
    "print(f\"False Detections: {metrics['false_detections']}\")\n",
    "print(f\"Detection Rate: {metrics['object_detection_rate']:.2%}\")\n",
    "print(f\"False Discovery Rate: {metrics['false_discovery_rate']:.2%}\")\n",
    "\n",
    "evaluator.visualize_samples(n_samples=100, show_analysis=True) #piemēru daudzums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5d1804-3555-404c-a717-1020ede3f4ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
